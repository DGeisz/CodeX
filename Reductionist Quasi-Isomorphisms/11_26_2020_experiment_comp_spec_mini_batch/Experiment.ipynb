{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CompSpec Network trained with Mini-batching\n",
    "\n",
    "## Intro\n",
    "\n",
    "* **Date**: 11/26/2020\n",
    "* **What**: This is the competitive specializing network from [the last experiment](../11_24_2020_experiment_competitive_specializing_network), except trained with mini-batching.\n",
    "* **Why**: The competitive specializing network blew my expectations out of the water, but it's still about 10x slower than [Krotov's and Hopfield's competitive algo](https://www.pnas.org/content/116/16/7723).  This algorithm converges typically with only one pass through the dataset, whereas Krotov's network takes like 100 passes.  If I can make this as fast as Krotov's network on a single pass through data, then bois, we'd be boolin'.\n",
    "* **Hopes**: I want this algorithm to train incredibly quickly.  Is that too much to ask for?\n",
    "* **Limitations**: I super don't know how to do mini-batching correctly.  Luckily, I have Dima's code to work off of, so hopefully it won't be a huge deal.\n",
    "\n",
    "## Technicals\n",
    "\n",
    "Basically, everything is the same as the algorithm I ended up with during the last experiment, but now I'm just trying to get it to work with mini-batches.  I'm not going to describe Mini-batching.  If you're reading this, you have an internet connection, so scoot-scoot your lil booty on over to Google and look it up.  It's incredibly straight forward.\n",
    "\n",
    "## Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tqdm import tqdm\n",
    "\n",
    "L = 28 * 28   #Size of mnist in pixels\n",
    "S = 60000     #Size of training set\n",
    "\n",
    "(train_X, train_y), (test_X, test_y) = mnist.load_data()\n",
    "train_X = train_X / 255.0\n",
    "\n",
    "flat_x = np.reshape(train_X, [-1, 1, L])\n",
    "flat_test = np.reshape(test_X, [-1, 1, L])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_weights(synapses, Kx, Ky): \n",
    "    yy=0\n",
    "    HM=np.zeros((28*Ky,28*Kx))\n",
    "    for y in range(Ky):\n",
    "        for x in range(Kx):\n",
    "            HM[y*28:(y+1)*28,x*28:(x+1)*28]=synapses[yy,:].reshape(28,28)\n",
    "            yy += 1\n",
    "    plt.clf()\n",
    "    nc=np.amax(np.absolute(HM))\n",
    "    \n",
    "    im=plt.imshow(HM,cmap='Greys',vmin=0,vmax=nc)\n",
    "    fig.colorbar(im,ticks=[0, np.amax(HM)])\n",
    "    plt.axis('off')\n",
    "    fig.canvas.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wta_classification(w, T_s):\n",
    "    flat_x = np.reshape(train_X, [-1, L])\n",
    "    flat_test = np.reshape(test_X, [-1, L])\n",
    "    \n",
    "    v = flat_x[:T_s]\n",
    "    train_lbls = train_y[:T_s]\n",
    "    \n",
    "    v = v / np.array([np.linalg.norm(v, axis=1)]).T\n",
    "    w = w / np.array([np.linalg.norm(w, axis=1)]).T\n",
    "    \n",
    "    wins = np.argmax(w @ (flat_x[:T_s, :]).T, axis=0)\n",
    "    \n",
    "    n_wins = np.zeros((w.shape[0], 10))\n",
    "    \n",
    "    for (n_i, lbl) in zip(wins, train_lbls):\n",
    "        n_wins[n_i][lbl] += 1\n",
    "        \n",
    "    n_cls = np.argmax(n_wins, axis=1)\n",
    "    print(\"Neuron classes:\", n_cls)\n",
    "    \n",
    "    num_test = test_y.shape[0]\n",
    "    test_v = flat_test / np.array([np.linalg.norm(flat_test, axis=1)]).T\n",
    "    \n",
    "    num_correct = 0\n",
    "    \n",
    "    incorrect = np.zeros(10)\n",
    "    \n",
    "    for i in range(num_test):\n",
    "        w_mul_v = w @ test_v[i].T\n",
    "        \n",
    "        n_max = np.argmax(w_mul_v)\n",
    "        \n",
    "        pre = n_cls[n_max]\n",
    "        if pre == test_y[i]:\n",
    "            num_correct += 1\n",
    "        else:\n",
    "            incorrect[test_y[i]] += 1\n",
    "            \n",
    "    print(\"Accuracy:\", str(num_correct * 100 / num_test) + '%')\n",
    "    print(\"Misclassifieds: \", incorrect)\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
